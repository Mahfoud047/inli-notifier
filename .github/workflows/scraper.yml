name: Run Scraper

on:
  schedule:
    - cron: "*/30 * * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Restore cache
        id: restore-cache
        uses: actions/cache@v3
        with:
         path: cache_ids.txt
         key: scraper-cache

      - name: Debug cache restore
        run: |
          echo "restore cache-hit=${{ steps.restore-cache.outputs.cache-hit }}"
          ls -la cache_ids.txt || true
          cat cache_ids.txt || echo "<no file/empty>"

      - name: Run scraper
        env:
          EMAIL_SENDER: ${{ secrets.EMAIL_SENDER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_RECEIVER: ${{ secrets.EMAIL_RECEIVER }}
          BASE_URL: ${{ secrets.BASE_URL }}
          URL: ${{ vars.URL }}
        run: python src/main.py

      - name: Show cache file before deciding to save
        id: cache-check
        run: |
          if [ -s cache_ids.txt ]; then
            echo "cache-empty=false" >> $GITHUB_OUTPUT
          else
            echo "cache-empty=true" >> $GITHUB_OUTPUT
          fi

      - name: Save cache (only if restore missed and file non-empty)
        if: steps.restore-cache.outputs.cache-hit != 'true' && steps.cache-check.outputs.cache-empty == 'false'
        uses: actions/cache@v3
        with:
          path: cache_ids.txt
          key: scraper-cache
